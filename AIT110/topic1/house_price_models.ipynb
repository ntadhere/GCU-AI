{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abad4911",
   "metadata": {},
   "source": [
    "# House Price Modeling: Linear & Multiple Regression\n",
    "This notebook loads the provided housing dataset and performs the requested analyses:\n",
    "1. Simple linear regression: **Price ~ Size**\n",
    "2. Simple linear regression: **Price ~ Sqft Living**\n",
    "3. Multiple linear regression: **Price ~ Sqft Living + Bedrooms + Age + Waterfront**\n",
    "4. Multiple linear regression: **Price ~ Size + Bedrooms + Age + Distance_to_city_center**\n",
    "5. Model evaluation with **R-squared**\n",
    "6. Assumption checks (residual plots, Q-Q plot) and discussion\n",
    "\n",
    "> **Note:** The code auto-detects columns with flexible names (e.g., `sqft_living` vs `size`) and derives `age` from `yr_built` and `date_sold` if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa83f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9285fe",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6987c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: dataset/housing_2.csv  |  shape: (36, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date:ÊThe date when the property was sold. Thi...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the temporal trends in property prices.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price:The sale price of the property in USD. T...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to predict.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bedrooms:The number of bedrooms in the propert...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             columns keep\n",
       "0  Date:ÊThe date when the property was sold. Thi...  Yes\n",
       "1            the temporal trends in property prices.  NaN\n",
       "2  Price:The sale price of the property in USD. T...  Yes\n",
       "3                                        to predict.  NaN\n",
       "4  Bedrooms:The number of bedrooms in the propert...  Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- find the data file ---\n",
    "data_path = None\n",
    "for cand in [\"dataset/housing_2.csv\", \"dataset/housing.csv\",\n",
    "             \"dataset/housing_2.xlsx\", \"dataset/housing.xlsx\"]:\n",
    "    if os.path.exists(cand):\n",
    "        data_path = cand\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\"Could not find dataset/housing_2 or dataset/housing (csv/xlsx).\")\n",
    "\n",
    "# --- robust loader: try multiple encodings / formats ---\n",
    "def robust_read(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in [\".xlsx\", \".xls\"]:\n",
    "        return pd.read_excel(path)\n",
    "    # try CSV with several encodings and parsers\n",
    "    encodings = [\"utf-8\", \"utf-8-sig\", \"latin1\", \"cp1252\"]\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            # engine='python' + sep=None lets pandas sniff odd delimiters\n",
    "            return pd.read_csv(path, encoding=enc, engine=\"python\", sep=None, on_bad_lines=\"skip\")\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            # try again with default engine in case dialect is clean\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc, on_bad_lines=\"skip\")\n",
    "            except Exception:\n",
    "                last_err = e\n",
    "                continue\n",
    "    # final attempt: replace undecodable bytes\n",
    "    return pd.read_csv(path, encoding=\"latin1\", engine=\"python\", sep=None,\n",
    "                       on_bad_lines=\"skip\", encoding_errors=\"replace\")\n",
    "\n",
    "df_raw = robust_read(data_path)\n",
    "\n",
    "# --- standardize column names ---\n",
    "df = df_raw.copy()\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "              .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "print(f\"Loaded: {data_path}  |  shape: {df.shape}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97d815",
   "metadata": {},
   "source": [
    "## Prepare and Harmonize Features\n",
    "We will map available columns to the required names, and derive **age** when possible from `yr_built` and `date_sold` (or `sale_date`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdf2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: dataset/housing_2.csv | shape=(36, 2)\n",
      "Columns: ['columns', 'keep']\n",
      "Mapped columns: {'price': None, 'size': None, 'sqft_living': None, 'bedrooms': None, 'age': None, 'distance_to_city_center': None, 'waterfront': '_waterfront_bin'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A price column was not found. Please set price_col manually after checking printed columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 151\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# --- 3) Build modeling frame (your pipeline continues) ---\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m price_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA price column was not found. Please set price_col manually after checking printed columns.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m df_model = df.copy()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m price_col == \u001b[33m'\u001b[39m\u001b[33mlog_price\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: A price column was not found. Please set price_col manually after checking printed columns."
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# --- 0) Locate & Load the dataset (robust to path + encoding) ---\n",
    "# Try common locations relative to where your notebook lives or project root\n",
    "candidate_paths = [\n",
    "    \"dataset/housing_2.csv\", \"dataset/housing.csv\",\n",
    "    \"AIT110/topic1/dataset/housing_2.csv\", \"AIT110/topic1/dataset/housing.csv\",\n",
    "    \"/mnt/data/housing_2.csv\", \"/mnt/data/housing.csv\",\n",
    "    \"dataset/housing_2.xlsx\", \"dataset/housing.xlsx\",\n",
    "    \"AIT110/topic1/dataset/housing_2.xlsx\", \"AIT110/topic1/dataset/housing.xlsx\",\n",
    "]\n",
    "\n",
    "data_path = next((p for p in candidate_paths if os.path.exists(p)), None)\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\"Could not find housing file in expected locations.\\n\"\n",
    "                            \"Checked:\\n\" + \"\\n\".join(candidate_paths))\n",
    "\n",
    "def robust_read(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in [\".xlsx\", \".xls\"]:\n",
    "        return pd.read_excel(path)\n",
    "    # Try multiple encodings for CSV\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc, engine=\"python\", sep=None, on_bad_lines=\"skip\")\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception:\n",
    "            # try default engine as a second attempt\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc, on_bad_lines=\"skip\")\n",
    "            except Exception:\n",
    "                continue\n",
    "    # Last resort: replace undecodable bytes\n",
    "    return pd.read_csv(path, encoding=\"latin1\", engine=\"python\", sep=None,\n",
    "                       on_bad_lines=\"skip\", encoding_errors=\"replace\")\n",
    "\n",
    "df_raw = robust_read(data_path)\n",
    "\n",
    "# --- 1) Standardize column names ---\n",
    "df = df_raw.copy()\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "              .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "print(f\"Loaded: {data_path} | shape={df.shape}\")\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# --- 2) Flexible column mapping (your pipeline, upgraded) ---\n",
    "def pick_col(candidates, contains=None):\n",
    "    \"\"\"Return the first exact match; if none, return the first column whose\n",
    "    name contains any of the 'contains' tokens (case-insensitive).\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if contains:\n",
    "        tokens = [t.lower() for t in contains]\n",
    "        for col in df.columns:\n",
    "            name = col.lower()\n",
    "            if any(t in name for t in tokens):\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "# Identify columns\n",
    "price_col = pick_col(\n",
    "    ['price', 'sale_price', 'log_price', 'saleprice', 'price_usd', 'median_house_value'],\n",
    "    contains=['price','value']\n",
    ")\n",
    "size_col  = pick_col(\n",
    "    ['size','sqft','sqft_size','sqft_living','living_area','sqftliving','gr_liv_area','total_sqft','square_feet'],\n",
    "    contains=['sqft','area','size']\n",
    ")\n",
    "sqft_col  = pick_col(\n",
    "    ['sqft_living','sqftliving','living_area','size','sqft','gr_liv_area','total_sqft','square_feet'],\n",
    "    contains=['sqft','living','area']\n",
    ")\n",
    "beds_col  = pick_col(\n",
    "    ['bedrooms','beds','bedroom','num_bedrooms','br'],\n",
    "    contains=['bed']\n",
    ")\n",
    "age_col   = pick_col(\n",
    "    ['age','age_auto','years_old'],\n",
    "    contains=['age']\n",
    ")\n",
    "dist_col  = pick_col(\n",
    "    ['distance_to_city_center','distance','dist_city_center','dist_to_city_center','distance_from_city','city_distance'],\n",
    "    contains=['dist','city']\n",
    ")\n",
    "water_col = pick_col(\n",
    "    ['waterfront','is_waterfront','on_water','water_front'],\n",
    "    contains=['water']\n",
    ")\n",
    "\n",
    "# Derive age if necessary from yr_built & sale date\n",
    "yr_built_col = pick_col(['yr_built','year_built','built_year'], contains=['built'])\n",
    "date_sold_col = pick_col(['date_sold','sale_date','sold_date','date'], contains=['date','sold'])\n",
    "\n",
    "def to_datetime_safe(s):\n",
    "    try:\n",
    "        return pd.to_datetime(s, errors='coerce', infer_datetime_format=True)\n",
    "    except Exception:\n",
    "        return pd.to_datetime(s, errors='coerce')\n",
    "\n",
    "if age_col is None:\n",
    "    if yr_built_col is not None and date_sold_col is not None:\n",
    "        ds = to_datetime_safe(df[date_sold_col])\n",
    "        ref_year = np.where(ds.notna(), ds.dt.year, datetime.now().year)\n",
    "        df['age_auto'] = (ref_year - pd.to_numeric(df[yr_built_col], errors='coerce')).astype(float)\n",
    "        age_col = 'age_auto'\n",
    "    elif yr_built_col is not None:\n",
    "        df['age_auto'] = (datetime.now().year - pd.to_numeric(df[yr_built_col], errors='coerce')).astype(float)\n",
    "        age_col = 'age_auto'\n",
    "\n",
    "# Ensure Waterfront becomes 0/1 (create if missing)\n",
    "if water_col is not None:\n",
    "    w = df[water_col].copy()\n",
    "    if w.dtype == 'O':\n",
    "        ws = w.astype(str).str.lower().str.strip()\n",
    "        truthy = {'1','true','yes','y','t'}\n",
    "        w = ws.apply(lambda x: 1.0 if x in truthy else (0.0 if x.replace('.','',1).isdigit() and float(x)==0 else np.nan))\n",
    "        w = w.fillna(0.0).astype(float)\n",
    "    else:\n",
    "        w = pd.to_numeric(w, errors='coerce').fillna(0.0)\n",
    "        if not set(np.unique(w.dropna())).issubset({0.0,1.0}):\n",
    "            w = (w > 0).astype(float)\n",
    "    df['_waterfront_bin'] = w.astype(float)\n",
    "    water_col = '_waterfront_bin'\n",
    "else:\n",
    "    df['_waterfront_bin'] = 0.0\n",
    "    water_col = '_waterfront_bin'\n",
    "\n",
    "print(\"Mapped columns:\", {\n",
    "    \"price\": price_col, \"size\": size_col, \"sqft_living\": sqft_col,\n",
    "    \"bedrooms\": beds_col, \"age\": age_col,\n",
    "    \"distance_to_city_center\": dist_col, \"waterfront\": water_col\n",
    "})\n",
    "\n",
    "# --- 3) Build modeling frame (your pipeline continues) ---\n",
    "if price_col is None:\n",
    "    raise ValueError(\"A price column was not found. Please set price_col manually after checking printed columns.\")\n",
    "\n",
    "df_model = df.copy()\n",
    "if price_col == 'log_price':\n",
    "    df_model['price'] = np.exp(df_model['log_price'])\n",
    "else:\n",
    "    df_model['price'] = pd.to_numeric(df_model[price_col], errors='coerce')\n",
    "\n",
    "# Coerce numerics for predictors that exist\n",
    "for c in [size_col, sqft_col, beds_col, age_col, dist_col, water_col]:\n",
    "    if c is not None:\n",
    "        df_model[c] = pd.to_numeric(df_model[c], errors='coerce')\n",
    "\n",
    "# Keep rows with price present\n",
    "df_model = df_model[df_model['price'].notna()].copy()\n",
    "display(df_model.head())\n",
    "\n",
    "# --- 4) Helper: OLS with intercept & pretty equation ---\n",
    "def fit_ols(y, X_df):\n",
    "    X = sm.add_constant(X_df, has_constant='add')\n",
    "    return sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "def regression_equation(model, y_name='Price'):\n",
    "    params = model.params\n",
    "    intercept = params.get('const', 0.0)\n",
    "    terms = [f\"{coef:.4f}*{name}\" for name, coef in params.items() if name != 'const']\n",
    "    rhs = f\"{intercept:.4f}\" + (\"\" if not terms else \" + \" + \" + \".join(terms))\n",
    "    return f\"{y_name} = {rhs}\"\n",
    "\n",
    "# --- 5) Model 1: Price ~ Size ---\n",
    "size_like = size_col if size_col is not None else sqft_col\n",
    "if size_like is None:\n",
    "    raise ValueError(\"No 'Size' or 'Sqft Living' style column found for Model 1.\")\n",
    "m1 = fit_ols(df_model['price'], df_model[[size_like]])\n",
    "print(\"\\n[Model 1] Price ~ Size-like\")\n",
    "print(regression_equation(m1, 'Price'))\n",
    "print(\"R-squared:\", round(m1.rsquared, 4))\n",
    "\n",
    "# --- 6) Model 2: Price ~ Sqft Living ---\n",
    "sqft_like = sqft_col if sqft_col is not None else size_col\n",
    "if sqft_like is None:\n",
    "    raise ValueError(\"No 'Sqft Living' or 'Size' style column found for Model 2.\")\n",
    "m2 = fit_ols(df_model['price'], df_model[[sqft_like]])\n",
    "print(\"\\n[Model 2] Price ~ Sqft Living-like\")\n",
    "print(regression_equation(m2, 'Price'))\n",
    "print(\"R-squared:\", round(m2.rsquared, 4))\n",
    "\n",
    "# --- 7) Model 3: Price ~ SqftLiving + Bedrooms + Age + Waterfront ---\n",
    "features_m3 = [c for c in [sqft_col, beds_col, age_col, water_col] if c is not None]\n",
    "if len(features_m3) == 0:\n",
    "    raise ValueError(\"No predictors available for Model 3.\")\n",
    "m3 = fit_ols(df_model['price'], df_model[features_m3])\n",
    "print(\"\\n[Model 3] Price ~\", \" + \".join(features_m3))\n",
    "print(regression_equation(m3, 'Price'))\n",
    "print(\"R-squared:\", round(m3.rsquared, 4))\n",
    "\n",
    "# Strongest impact via standardized coefficients\n",
    "X_m3 = df_model[features_m3].copy().dropna()\n",
    "y_m3 = df_model.loc[X_m3.index, 'price']\n",
    "X_std = (X_m3 - X_m3.mean())/X_m3.std(ddof=0)\n",
    "m3_std = fit_ols(y_m3, X_std)\n",
    "coef_abs = m3_std.params.drop('const').abs().sort_values(ascending=False)\n",
    "print(\"Approx strongest impact (|standardized coef|):\")\n",
    "print(coef_abs.head())\n",
    "\n",
    "# --- 8) Model 4: Price ~ Size + Bedrooms + Age + Distance_to_city_center ---\n",
    "features_m4 = [c for c in [size_col, beds_col, age_col, dist_col] if c is not None]\n",
    "if len(features_m4) == 0:\n",
    "    raise ValueError(\"No predictors available for Model 4.\")\n",
    "m4 = fit_ols(df_model['price'], df_model[features_m4])\n",
    "print(\"\\n[Model 4] Price ~\", \" + \".join(features_m4))\n",
    "print(regression_equation(m4, 'Price'))\n",
    "print(\"R-squared:\", round(m4.rsquared, 4))\n",
    "\n",
    "X_m4 = df_model[features_m4].copy().dropna()\n",
    "y_m4 = df_model.loc[X_m4.index, 'price']\n",
    "X_std4 = (X_m4 - X_m4.mean())/X_m4.std(ddof=0)\n",
    "m4_std = fit_ols(y_m4, X_std4)\n",
    "coef_abs4 = m4_std.params.drop('const').abs().sort_values(ascending=False)\n",
    "print(\"Approx strongest impact (|standardized coef|):\")\n",
    "print(coef_abs4.head())\n",
    "\n",
    "# --- 9) Compare R^2 across models ---\n",
    "eval_df = pd.DataFrame([\n",
    "    {\"model\": f\"Price ~ {size_like}\", \"r_squared\": round(m1.rsquared, 4)},\n",
    "    {\"model\": f\"Price ~ {sqft_like}\", \"r_squared\": round(m2.rsquared, 4)},\n",
    "    {\"model\": f\"Price ~ {' + '.join(features_m3)}\", \"r_squared\": round(m3.rsquared, 4)},\n",
    "    {\"model\": f\"Price ~ {' + '.join(features_m4)}\", \"r_squared\": round(m4.rsquared, 4)},\n",
    "])\n",
    "display(eval_df)\n",
    "\n",
    "# --- 10) Residual diagnostics (use Model 4; fallback to Model 3) ---\n",
    "model_diag = m4 if 'm4' in globals() else m3\n",
    "fitted = model_diag.fittedvalues\n",
    "resid = model_diag.resid\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fitted, resid, alpha=0.6)\n",
    "plt.axhline(0, linestyle='--')\n",
    "plt.title('Residuals vs Fitted')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "fig = sm.qqplot(resid, line='45')\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fitted, np.sqrt(np.abs(resid)), alpha=0.6)\n",
    "plt.title('Scale-Location (sqrt|Residuals| vs Fitted)')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('sqrt(|Residuals|)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAssumption guide:\")\n",
    "print(\"- Linearity: Residuals should randomly scatter around 0.\")\n",
    "print(\"- Homoscedasticity: Roughly constant spread of residuals.\")\n",
    "print(\"- Normality: Q-Q close to 45° line. If not, consider transforms (e.g., log(Price)).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd755f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols(y, X_df):\n",
    "    X = sm.add_constant(X_df, has_constant='add')\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "    return model\n",
    "\n",
    "def regression_equation(model, y_name='Price'):\n",
    "    params = model.params\n",
    "    terms = []\n",
    "    intercept = params.get('const', 0.0)\n",
    "    for name, coef in params.items():\n",
    "        if name == 'const':\n",
    "            continue\n",
    "        terms.append(f\"{coef:.4f}*{name}\")\n",
    "    rhs = f\"{intercept:.4f} + \" + \" + \".join(terms) if terms else f\"{intercept:.4f}\"\n",
    "    return f\"{y_name} = {rhs}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fdf17",
   "metadata": {},
   "source": [
    "## 1) Simple Linear Regression — Price ~ Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc433c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a size-like feature (fall back to sqft_col if needed)\n",
    "size_like = size_col if size_col is not None else sqft_col\n",
    "if size_like is None:\n",
    "    raise ValueError(\"No 'Size' or 'Sqft Living' column found for the simple model.\")\n",
    "\n",
    "m1 = fit_ols(df_model['price'], df_model[[size_like]])\n",
    "print(\"Regression equation:\")\n",
    "print(regression_equation(m1, 'Price'))\n",
    "print(\"\\nCoefficients:\\n\", m1.params)\n",
    "print(\"\\nR-squared:\", round(m1.rsquared, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456682b0",
   "metadata": {},
   "source": [
    "**Interpretation (automated):** The slope is the change in predicted **Price** for a one-unit increase in **Size** (square feet). The intercept is the predicted **Price** when **Size = 0** (a baseline, often outside realistic range)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ace19",
   "metadata": {},
   "source": [
    "## 2) Simple Linear Regression — Price ~ Sqft Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd295cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a sqft_living-like feature (fall back to size_col if needed)\n",
    "sqft_like = sqft_col if sqft_col is not None else size_col\n",
    "if sqft_like is None:\n",
    "    raise ValueError(\"No 'Sqft Living' or 'Size' column found for this model.\")\n",
    "\n",
    "m2 = fit_ols(df_model['price'], df_model[[sqft_like]])\n",
    "print(\"Regression equation:\")\n",
    "print(regression_equation(m2, 'Price'))\n",
    "print(\"\\nCoefficients:\\n\", m2.params)\n",
    "print(\"\\nR-squared:\", round(m2.rsquared, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b3c62",
   "metadata": {},
   "source": [
    "**Interpretation (automated):** The slope is the change in predicted **Price** per additional square foot of **Sqft Living**. The intercept is the baseline **Price** at 0 square feet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936fca2",
   "metadata": {},
   "source": [
    "## 3) Multiple Linear Regression — Price ~ Sqft Living + Bedrooms + Age + Waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature list for model 3\n",
    "features_m3 = []\n",
    "names_m3 = {'sqft_living': sqft_col, 'bedrooms': beds_col, 'age': age_col, 'waterfront': water_col}\n",
    "\n",
    "for k, c in names_m3.items():\n",
    "    if c is not None and c in df_model.columns:\n",
    "        features_m3.append(c)\n",
    "\n",
    "if len(features_m3) == 0:\n",
    "    raise ValueError(\"No predictors available for Model 3.\")\n",
    "\n",
    "m3 = fit_ols(df_model['price'], df_model[features_m3])\n",
    "print(\"Regression equation:\")\n",
    "print(regression_equation(m3, 'Price'))\n",
    "print(\"\\nCoefficients:\\n\", m3.params)\n",
    "print(\"\\nR-squared:\", round(m3.rsquared, 4))\n",
    "\n",
    "# Identify strongest impact by absolute standardized coefficient (simple proxy)\n",
    "X_m3 = df_model[features_m3].copy().dropna()\n",
    "y_m3 = df_model.loc[X_m3.index, 'price']\n",
    "X_std = (X_m3 - X_m3.mean())/X_m3.std(ddof=0)\n",
    "m3_std = fit_ols(y_m3, X_std)\n",
    "coef_abs = m3_std.params.drop('const').abs().sort_values(ascending=False)\n",
    "print(\"\\nApprox. strongest impact (by |standardized coef|):\\n\", coef_abs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52887f14",
   "metadata": {},
   "source": [
    "> **Interpretation Tip:** Positive coefficients increase price; negative coefficients decrease price. The variable with the largest absolute standardized coefficient generally has the strongest impact (holding other variables constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9ad50",
   "metadata": {},
   "source": [
    "## 4) Multiple Linear Regression — Price ~ Size + Bedrooms + Age + Distance_to_city_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature list for model 4\n",
    "features_m4 = []\n",
    "names_m4 = {'size': size_col, 'bedrooms': beds_col, 'age': age_col, 'distance_to_city_center': dist_col}\n",
    "\n",
    "for k, c in names_m4.items():\n",
    "    if c is not None and c in df_model.columns:\n",
    "        features_m4.append(c)\n",
    "\n",
    "if len(features_m4) == 0:\n",
    "    raise ValueError(\"No predictors available for Model 4.\")\n",
    "\n",
    "m4 = fit_ols(df_model['price'], df_model[features_m4])\n",
    "print(\"Regression equation:\")\n",
    "print(regression_equation(m4, 'Price'))\n",
    "print(\"\\nCoefficients:\\n\", m4.params)\n",
    "print(\"\\nR-squared:\", round(m4.rsquared, 4))\n",
    "\n",
    "# Strongest impact via standardized coefficients\n",
    "X_m4 = df_model[features_m4].copy().dropna()\n",
    "y_m4 = df_model.loc[X_m4.index, 'price']\n",
    "X_std4 = (X_m4 - X_m4.mean())/X_m4.std(ddof=0)\n",
    "m4_std = fit_ols(y_m4, X_std4)\n",
    "coef_abs4 = m4_std.params.drop('const').abs().sort_values(ascending=False)\n",
    "print(\"\\nApprox. strongest impact (by |standardized coef|):\\n\", coef_abs4.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d35c6",
   "metadata": {},
   "source": [
    "## 5) Model Evaluation — R-squared and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append({\"model\": f\"Price ~ {size_like}\", \"r_squared\": round(m1.rsquared,4)})\n",
    "results.append({\"model\": f\"Price ~ {sqft_like}\", \"r_squared\": round(m2.rsquared,4)})\n",
    "results.append({\"model\": f\"Price ~ {' + '.join(features_m3)}\", \"r_squared\": round(m3.rsquared,4)})\n",
    "results.append({\"model\": f\"Price ~ {' + '.join(features_m4)}\", \"r_squared\": round(m4.rsquared,4)})\n",
    "eval_df = pd.DataFrame(results)\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e9208",
   "metadata": {},
   "source": [
    "**Interpretation:** Higher **R-squared** indicates a better fit (more variance in **Price** explained). Multiple regression models typically have higher R-squared than simple models because they use more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f8b7f",
   "metadata": {},
   "source": [
    "## 6) Assumption Checks — Residual Diagnostics (using Model 4 by default)\n",
    "We visualize residuals vs. fitted values and a Q-Q plot to assess normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model for diagnostics (prefer model 4; if not available, fallback to model 3)\n",
    "model_diag = m4 if 'm4' in globals() else m3\n",
    "\n",
    "fitted = model_diag.fittedvalues\n",
    "resid = model_diag.resid\n",
    "\n",
    "# Residuals vs Fitted\n",
    "plt.figure()\n",
    "plt.scatter(fitted, resid, alpha=0.6)\n",
    "plt.axhline(0, linestyle='--')\n",
    "plt.title('Residuals vs Fitted')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for residuals\n",
    "fig = sm.qqplot(resid, line='45')\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Scale-Location (Spread vs Fitted) — optional but helpful\n",
    "plt.figure()\n",
    "plt.scatter(fitted, np.sqrt(np.abs(resid)), alpha=0.6)\n",
    "plt.title('Scale-Location (sqrt|Residuals| vs Fitted)')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('sqrt(|Residuals|)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93761efe",
   "metadata": {},
   "source": [
    "### Discussion of Assumptions\n",
    "- **Linearity:** Residuals should scatter randomly around zero (no clear curves). If curved patterns appear, consider adding polynomial terms or transforming predictors.\n",
    "- **Homoscedasticity (constant variance):** The spread of residuals should be roughly constant across fitted values. If you see a fan-shaped pattern, try transforming **Price** (e.g., log) or using weighted least squares.\n",
    "- **Normality of residuals:** Q-Q plot points should lie close to the 45° line. Strong deviations suggest non-normality; consider transforming **Price** or using robust methods.\n",
    "- **Outliers/Influence:** Investigate extreme residuals or high-leverage points (e.g., Cook’s distance) and validate data quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
