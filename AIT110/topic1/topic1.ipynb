{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1268a26f",
   "metadata": {},
   "source": [
    "\n",
    "# Statistical Learning & Linear Regression — Jupyter Notebook Template\n",
    "\n",
    "This notebook is structured to match the assignment prompt.  \n",
    "Run each cell in order. If you do **not** have `house_prices.csv` in the notebook folder, the notebook will **auto‑generate** a synthetic dataset with plausible values so you can still complete the tasks.\n",
    "\n",
    "> **Tip:** If packages are missing, run the setup cell in **Part 0**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850931c",
   "metadata": {},
   "source": [
    "\n",
    "## Part 0 — Environment Setup (Run if needed)\n",
    "\n",
    "Use this cell to install any missing packages. If you already have them, you can skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If needed, uncomment the lines below to install packages in this environment.\n",
    "# Note: In conda/miniforge, prefer: conda install pandas numpy scikit-learn matplotlib scipy statsmodels\n",
    "# Otherwise, pip installs will work inside your active environment.\n",
    "\n",
    "# %pip install -q pandas numpy scikit-learn matplotlib scipy statsmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9707a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 1 — Theoretical Concepts\n",
    "\n",
    "### 1) Define the following in the context of statistical learning\n",
    "a) **Training error** — *Your answer here.*  \n",
    "b) **Test error** — *Your answer here.*  \n",
    "c) **Bias–variance trade‑off** — *Your answer here.*  \n",
    "d) **Overfitting** — *Your answer here.*  \n",
    "e) **Model complexity** — *Your answer here.*\n",
    "\n",
    "### 2) Parametric vs. Nonparametric Models\n",
    "- **Explain the difference.** *Your answer here.*  \n",
    "- **Give an example of each.** *Your answer here.*\n",
    "\n",
    "### 3) Bias–Variance Trade‑off (Discussion)\n",
    "- **Discuss how model complexity affects performance.** *Your answer here.*  \n",
    "- **Example of overfitting with a complex model.** *Your answer here.*  \n",
    "- **Example of underfitting with an overly simple model.** *Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1913f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 2 — Linear Regression\n",
    "\n",
    "You are provided with (or will generate) a dataset with columns:\n",
    "\n",
    "- `Price` *(USD, dependent variable)*  \n",
    "- `Size` *(square feet)*  \n",
    "- `Bedrooms` *(integer count)*  \n",
    "- `Age` *(years)*  \n",
    "- `Distance_to_city_center` *(miles)*\n",
    "\n",
    "### 0) Load dataset (or auto‑generate synthetic data)\n",
    "\n",
    "- If a file named **`house_prices.csv`** is found in the working directory, it will be loaded.  \n",
    "- Otherwise, the notebook will **generate** a synthetic dataset of 500 rows with realistic relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "csv_path = \"house_prices.csv\"\n",
    "\n",
    "def generate_synthetic_data(n=500, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Base features\n",
    "    Size = rng.normal(loc=1800, scale=500, size=n).clip(500, 4500)  # sq ft\n",
    "    Bedrooms = np.round((Size / 700) + rng.normal(0, 0.6, size=n)).clip(1, 8).astype(int)\n",
    "    Age = rng.integers(0, 80, size=n)  # years\n",
    "    Distance = np.abs(rng.normal(loc=8, scale=5, size=n))  # miles to center\n",
    "    \n",
    "    # Price model (true) with noise\n",
    "    # Larger size => higher price; more bedrooms => higher price; older => lower; farther => lower\n",
    "    base = 50000\n",
    "    price = (\n",
    "        base\n",
    "        + 220 * Size\n",
    "        + 15000 * Bedrooms\n",
    "        - 1200 * Age\n",
    "        - 8000 * Distance\n",
    "        + rng.normal(0, 35000, size=n)  # noise\n",
    "    )\n",
    "    price = np.clip(price, 50000, None)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Price\": price.astype(float),\n",
    "        \"Size\": Size.astype(float),\n",
    "        \"Bedrooms\": Bedrooms.astype(int),\n",
    "        \"Age\": Age.astype(int),\n",
    "        \"Distance_to_city_center\": Distance.astype(float),\n",
    "    })\n",
    "    return df\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {csv_path} with shape {df.shape}\")\n",
    "else:\n",
    "    df = generate_synthetic_data(n=500, seed=42)\n",
    "    print(\"Synthetic dataset generated (since 'house_prices.csv' was not found).\")\n",
    "    \n",
    "# Basic sanity check\n",
    "display(df.head())\n",
    "print(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b177ddf",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Simple Linear Regression: `Price ~ Size`\n",
    "\n",
    "- **Task (a)**: Provide the regression equation.  \n",
    "- **Task (b)**: Interpret the slope and intercept in context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb976d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Simple LR with Size only\n",
    "X_simple = df[[\"Size\"]].values\n",
    "y = df[\"Price\"].values\n",
    "\n",
    "simple_lr = LinearRegression()\n",
    "simple_lr.fit(X_simple, y)\n",
    "\n",
    "intercept = float(simple_lr.intercept_)\n",
    "slope = float(simple_lr.coef_[0])\n",
    "\n",
    "print(\"Simple Linear Regression: Price = b0 + b1 * Size\")\n",
    "print(f\"b0 (intercept): {intercept:,.2f}\")\n",
    "print(f\"b1 (slope for Size): {slope:,.2f}\")\n",
    "\n",
    "# Example prediction for interpretation\n",
    "example_size = 2000\n",
    "pred_price = simple_lr.predict([[example_size]])[0]\n",
    "print(f\"Predicted Price for Size={example_size} sq ft: {pred_price:,.2f} USD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc184112",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation (write in your own words):**  \n",
    "- **Intercept (b0):** *Your answer here — expected price when Size = 0 (often not meaningful physically).*  \n",
    "- **Slope (b1):** *Your answer here — expected change in price (USD) for a 1 sq ft increase in Size, holding all else constant (in this simple model).*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1881b",
   "metadata": {},
   "source": [
    "\n",
    "### 2) Multiple Linear Regression: `Price ~ Size + Bedrooms + Age + Distance_to_city_center`\n",
    "\n",
    "- **Task (a)**: Provide the regression equation.  \n",
    "- **Task (b)**: Interpret the coefficients. Which variable has the strongest impact on price?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfaa60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\"Size\", \"Bedrooms\", \"Age\", \"Distance_to_city_center\"]\n",
    "X_multi = df[features].values\n",
    "y = df[\"Price\"].values\n",
    "\n",
    "multi_lr = LinearRegression()\n",
    "multi_lr.fit(X_multi, y)\n",
    "\n",
    "print(\"Multiple Linear Regression: Price = b0 + b1*Size + b2*Bedrooms + b3*Age + b4*Distance_to_city_center\")\n",
    "print(f\"Intercept (b0): {multi_lr.intercept_:,.2f}\")\n",
    "for name, coef in zip(features, multi_lr.coef_):\n",
    "    print(f\"{name:>25}: {coef:,.2f}\")\n",
    "\n",
    "# Standardized coefficients to compare relative impact\n",
    "std_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "std_pipeline.fit(X_multi, y)\n",
    "std_coefs = std_pipeline.named_steps[\"lr\"].coef_\n",
    "\n",
    "print(\"\\nStandardized coefficients (features z-scored; larger |coef| => stronger impact):\")\n",
    "for name, coef in zip(features, std_coefs):\n",
    "    print(f\"{name:>25}: {coef:,.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92580d",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation (write in your own words):**  \n",
    "- Explain the meaning of each coefficient in context (holding other variables constant).  \n",
    "- Use the **standardized coefficients** (by absolute value) to argue which variable has the strongest impact.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e14a57",
   "metadata": {},
   "source": [
    "\n",
    "### 3) Evaluate Model Fit\n",
    "\n",
    "- Compute **R-squared** for both the simple and multiple models.  \n",
    "- Explain what each R-squared tells you.  \n",
    "- Compare which model fits better and why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# R-squared for simple model\n",
    "y_hat_simple = simple_lr.predict(X_simple)\n",
    "r2_simple = r2_score(y, y_hat_simple)\n",
    "\n",
    "# R-squared for multiple model\n",
    "y_hat_multi = multi_lr.predict(X_multi)\n",
    "r2_multi = r2_score(y, y_hat_multi)\n",
    "\n",
    "print(f\"R-squared (Simple: Size only): {r2_simple:.4f}\")\n",
    "print(f\"R-squared (Multiple: all features): {r2_multi:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05451c",
   "metadata": {},
   "source": [
    "\n",
    "**Your discussion here:**  \n",
    "- What does each R-squared value indicate about goodness-of-fit?  \n",
    "- Which model fits better? Why might that be?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae46587",
   "metadata": {},
   "source": [
    "\n",
    "### 4) Check Linear Regression Assumptions (Multiple Model)\n",
    "\n",
    "- Create residual plots for the multiple regression model.  \n",
    "- Discuss linearity, homoscedasticity, and normality. If assumptions seem violated, suggest remedies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Residuals\n",
    "residuals = y - y_hat_multi\n",
    "fitted = y_hat_multi\n",
    "\n",
    "# Residuals vs Fitted\n",
    "plt.figure()\n",
    "plt.scatter(fitted, residuals, s=12)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Fitted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted (Multiple LR)\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.figure()\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for normality\n",
    "plt.figure()\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q–Q Plot of Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158dc43",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation (write in your own words):**  \n",
    "- **Linearity:** *Your answer here.*  \n",
    "- **Homoscedasticity (constant variance):** *Your answer here.*  \n",
    "- **Normality of residuals:** *Your answer here.*  \n",
    "- **Potential remedies if violated:** transformations (e.g., log `Price`), add interaction terms, remove/trim outliers, or try regularization/other models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392de7dd",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 3 — Model Selection and Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246e1e3",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Train/Test Split & MSE\n",
    "\n",
    "- Split data into **80% train / 20% test**.  \n",
    "- Fit the **multiple linear regression** on the training set.  \n",
    "- Compute **MSE** on both training and test sets; compare generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fa1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df[features].values\n",
    "y = df[\"Price\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123, shuffle=True)\n",
    "\n",
    "lr_tt = LinearRegression()\n",
    "lr_tt.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lr_tt.predict(X_train)\n",
    "y_test_pred  = lr_tt.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test  = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train MSE: {mse_train:,.2f}\")\n",
    "print(f\"Test  MSE: {mse_test:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f88951",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation (write in your own words):**  \n",
    "- Compare Train vs. Test MSE. What does this say about generalization?  \n",
    "- Signs of **overfitting**: Train MSE ≪ Test MSE.  \n",
    "- Signs of **underfitting**: Both MSEs high and similar; low R².\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd98cbe",
   "metadata": {},
   "source": [
    "\n",
    "### 2) Overfitting vs. Underfitting\n",
    "\n",
    "Based on Train/Test results, discuss whether the model is overfitting or underfitting.  \n",
    "*Your answer here — include ideas like cross‑validation, regularization (Ridge/Lasso), adding/removing features, transformations, or collecting more data.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56791e85",
   "metadata": {},
   "source": [
    "\n",
    "### 3) Feature Engineering Idea\n",
    "\n",
    "Suggest **one additional variable** that could improve predictions (e.g., lot size, neighborhood quality score, renovation status, HOA fees, local school rating index).  \n",
    "Justify your choice based on the **housing** context. *Your answer here.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722e21a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Submission Checklist\n",
    "\n",
    "- Clear sections matching **Part 1–3**.  \n",
    "- Comments explaining each step.  \n",
    "- All outputs and visualizations included (after you **run all**).  \n",
    "- **Screencast (4–5 min)** covering:  \n",
    "  - Key theoretical concepts (Part 1).  \n",
    "  - Data, models, and code walkthrough (Part 2–3).  \n",
    "  - Interpretation of results and diagnostics.  \n",
    "  - What you would improve next and why.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
